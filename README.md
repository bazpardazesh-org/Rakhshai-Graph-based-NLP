# Rakhshai Graph-based NLP for Persian – کتابخانهٔ پردازش زبان طبیعی مبتنی بر گراف برای زبان فارسی

[![CI](https://github.com/bazpardazesh-org/Rakhshai-Graph-based-NLP/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/bazpardazesh-org/Rakhshai-Graph-based-NLP/actions/workflows/ci.yml)


For documentation visit [docs/](docs/index.md).

کتابخانهٔ **Rakhshai Graph-based NLP** یک کتابخانهٔ پژوهشی است که به شما کمک می‌کند متن‌های
فارسی را به ساختارهای گرافی تبدیل کنید و سپس با الگوریتم‌های
گرافی آن‌ها را تحلیل نمایید. این ابزار با الهام از مدل‌های
TextGCN، GCN و GraphSAGE طراحی شده است تا بتوانید وظایف مختلفی
مانند طبقه‌بندی متن، خلاصه‌سازی، توصیه‌گر محتوا، تشخیص نفرت‌پراکنی و
تحلیل شبکه‌های اجتماعی را با استفاده از گراف‌های کلمات و اسناد
انجام دهید. در این مستند تلاش کرده‌ایم همهٔ بخش‌های پروژه را
معرفی کنیم و مثال‌هایی برای آزمایش هر قسمت ارائه دهیم.
- این نسخه غیرتجاری توسط تیم توسعه [RakhshAI](https://rakhshai.com/) وابسته به شرکت آریا هامان مهر پارسه ایجاد و توسعه داده شده است.


## ویژگی‌های برجسته

- ساخت انواع گراف‌های متنی (هم‌رخدادی، TextGraph، گراف سند، وابستگی و معنایی).
- مدل‌های گرافی GCN، GraphSAGE و GAT که همگی با PyTorch Geometric پیاده‌سازی شده‌اند و از GPU پشتیبانی می‌کنند.
- وظایف آمادهٔ پژوهشی مانند طبقه‌بندی، خلاصه‌سازی، توصیه‌گر محتوا، تشخیص نفرت‌پراکنی و تحلیل شبکهٔ اجتماعی.
- ابزارهای کمکی شامل توکنایزر، پیش‌پردازش متن، معیارهای ارزیابی و ماژول تبیین اولیه.
- رابط خط فرمان `rgnn-cli` برای اجرای سریع آزمایش‌ها.
- مستندات کامل در پوشهٔ `docs/` و مجموعهٔ تست‌ها برای اطمینان از صحت عملکرد.

## چرا گراف؟

روش‌های مبتنی بر گراف اجازه می‌دهند ساختارهای جهانی و محلی را که
در دادهٔ متنی وجود دارد به‌طور همزمان مدل کنیم. به عنوان نمونه،
الگوریتم TextGCN اسناد و کلمات را گره‌های یک گراف در نظر می‌گیرد و
وزن edges را براساس هم‌رخدادی (PMI) و TF‑IDF تعیین می‌کند؛ سپس
یک شبکهٔ عصبی گرافی (GCN) بر روی این گراف آموزش می‌بیند تا
برچسب‌های اسناد را پیش‌بینی کند. در
مدل GraphSAGE نیز به‌جای ذخیرهٔ یک embedding ثابت برای هر گره،
تابعی یادگیری می‌شود که با نمونه‌گیری و تجمیع ویژگی‌های
همسایگی، embedding گره‌های دیده‌نشده را نیز تولید می‌کند.

## مؤلفه‌های اصلی

### ۱. ماژول‌های ساخت گراف

این بسته چندین تابع برای ساخت انواع گراف‌ متن فراهم می‌کند. هر
کدام برای کاربردی خاص مناسب است:

| ماژول | توضیح کوتاه |
|------|-------------|
| **`build_cooccurrence_graph`** | از یک فهرست اسناد توکن‌شده، گراف هم‌رخدادی می‌سازد. گره‌ها کلمات هستند و وزن edges تعداد دفعات هم‌رخدادی در یک پنجرهٔ لغتی است. این روش زیرساخت بسیاری از مدل‌های گرافی است و می‌توان آن را برای استخراج کلمات کلیدی یا بررسی همبستگی‌ها به کار برد. |
| **`build_text_graph`** | یک گراف دو-بخشی شامل گره‌های کلمه و سند تولید می‌کند. وزن edgesی کلمه–کلمه با شاخص PMI محاسبه می‌شود و edgesی کلمه–سند بر اساس TF‑IDF تعریف می‌شوند. این ساختار برای طبقه‌بندی اسناد با GCN بسیار مناسب است. |
| **`build_document_graph`** | شباهت بین اسناد را با استفاده از بردارهای TF‑IDF یا embedding از پیش‌محاسبه‌شده می‌سنجد و گرافی ایجاد می‌کند که در آن گره‌ها اسناد و وزن edges میزان شباهت کسینوسی هستند. این گراف می‌تواند برای توصیه‌گرها یا خوشه‌بندی به کار رود. |
| **`build_dependency_graph`** | با استفاده از تحلیل وابستگی (dependency parsing) در کتابخانهٔ [Stanza](https://stanfordnlp.github.io/stanza/)، ساختار نحوی جملات استخراج می‌شود و بین کلمات edgesیی بر اساس رابطهٔ دستوری آن‌ها ایجاد می‌گردد. Stanza یک بستهٔ کامل است که متن را به جملات و کلمات تقسیم می‌کند، نقش دستوری و ویژگی‌های صرفی را تعیین می‌کند و تجزیهٔ نحوی و تشخیص موجودیت نام‌دار را انجام می‌دهد. |
| **`build_semantic_graph`** | این ماژول (فعلاً) گراف معنایی تهی بازمی‌گرداند. هدف آن در آینده استفاده از پایگاه‌های واژگانی مانند WordNet است که واژه‌ها را در مجموعه‌های هم‌معنا گروه‌بندی می‌کند و روابط معنایی میان آن‌ها را ذخیره می‌نماید. در حال حاضر WordNet فارسی کامل وجود ندارد، اما ساختار این تابع آمادهٔ توسعه است. |

### ۲. ماژول‌های مدل‌سازی

پس از ساخت گراف، برای استخراج الگوها می‌توان از مدل‌های مختلف استفاده کرد:

- **Graph Convolutional Network (GCN):** یک شبکهٔ دولایه که با استفاده از ماتریس مجاورت نرمال‌شده، ویژگی‌های گره‌ها را منتشر می‌کند و سپس با یک تابع غیرخطی (ReLU) و یک لایهٔ نهایی softmax، برچسب هر گره را پیش‌بینی می‌کند. این مدل برای طبقه‌بندی گره‌ها در گراف‌های ثابت به کار می‌رود.

- **GraphSAGE:** چارچوبی برای یادگیری استقرایی که از نمونه‌گیری و تجمیع ویژگی‌های همسایگان برای تولید embedding استفاده می‌کند. این روش قادر است برای گره‌های جدید (که در زمان آموزش دیده نشده‌اند) نیز embedding بسازد.

- **Graph Attention Network (GAT) – نسخهٔ آزمایشی:** پیاده‌سازی اولیهٔ یک لایهٔ GAT برای استفاده‌های آینده (مثلاً خلاصه‌سازی مبتنی بر توجه). هنوز مدل کامل خلاصه‌سازی با GAT در این نسخه ارائه نشده است.

### ۳. وظایف تحلیلی

- **طبقه‌بندی متن:** با استفاده از `build_text_graph` می‌توانید یک گراف شامل کلمات و اسناد بسازید و سپس با `train_gcn_classifier` یک مدل GCN آموزش دهید تا اسناد را در دسته‌بندی‌های مختلف قرار دهد. مثال کامل در ادامه آمده است.

- **خلاصه‌سازی:** الگوریتم TextRank جملات را به‌صورت گره‌های یک گراف در نظر می‌گیرد و با اجرای PageRank، مهم‌ترین جملات را انتخاب می‌کند. ماژول `textrank_summarise` متن فارسی را به جملات تقسیم می‌کند، گراف شباهت جملات می‌سازد و سپس با PageRank مهم‌ترین جملات را استخراج می‌کند.

- **توصیه‌گر محتوا:** `recommend_similar` با ساختن گراف شباهت اسناد، نزدیک‌ترین اسناد به یک پرسش یا سند جدید را برمی‌گرداند. این کار با محاسبهٔ TF‑IDF و شباهت کسینوسی انجام می‌شود.

- **تشخیص نفرت‌پراکنی:** `contains_hate_speech` یک پیاده‌سازی ساده و ابتدایی برای شناسایی وجود عبارات نفرت‌انگیز در متن است. برای کاربردهای جدی باید داده‌های برچسب‌خورده جمع‌آوری و یک مدل گرافی قدرتمند آموزش داده شود.

- **تحلیل شبکه‌های اجتماعی:** `compute_social_embeddings` با استفاده از GraphSAGE embedding گره‌ها را بر اساس ساختار شبکه تولید می‌کند. این embedding می‌تواند برای خوشه‌بندی کاربران، پیش‌بینی لینک یا تحلیل نفوذ استفاده شود.

## ساختار پروژه

```
rakhshai_graph_nlp/
├── features/        # توکنایز و پیش‌پردازش متن
├── graphs/          # توابع ساخت گراف
├── models/          # مدل‌های GNN
├── tasks/           # وظایف کاربردی
├── explain/         # ابزارهای تبیین اولیه
├── metrics.py       # معیارهای ارزیابی
├── cli.py           # رابط خط فرمان rgnn-cli
└── utils/           # توابع کمکی

docs/                # مستندات MkDocs
tests/               # تست‌های واحد
```

## نصب و راه‌اندازی

این مخزن با پایتون ۳٫۹ یا جدیدتر کار می‌کند. برای نصب نسخهٔ توسعه‌ای و
افزودنی‌های اختیاری می‌توانید از ماتریس زیر استفاده کنید:

```bash
pip install -e .            # هسته
pip install -e .[sparse]    # توابع گراف تنک
pip install -e .[ml]        # وابستگی‌های یادگیری ماشین
pip install -e .[fa]        # پشتیبانی Faiss
pip install -e .[docs]      # ساخت مستندات
```

برخی از قابلیت‌ها مانند ساخت گراف شباهت اسناد (`build_document_graph`)، توصیه‌گر محتوا (`recommend_similar`) و خلاصه‌سازی مبتنی بر TextRank (`textrank_summarise`) برای محاسبات TF‑IDF و شباهت کسینوسی به کتابخانهٔ `scikit-learn` وابسته‌اند. این وابستگی با گزینهٔ افزونهٔ `ml` نصب می‌شود.

پس از نصب وابستگی‌ها می‌توانید تست‌های پروژه را اجرا کنید تا از صحت نصب مطمئن شوید:

```bash
pytest
```

برای اجرای یک آزمایش کوچک خط فرمان که یک مدل GCN ساده را اجرا کرده و دقت حاصل را چاپ می‌کند (با امکان انتخاب پردازنده یا GPU):

```bash
rgnn-cli --model gcn --device cuda
```

نمونهٔ خروجی این فرمان چیزی شبیه زیر خواهد بود (در صورت نبود GPU می‌توانید `--device cpu` را انتخاب کنید):

```
INFO - model=gcn accuracy=0.333
```

## مثال‌ها و آزمایش‌ها

در این بخش نحوهٔ استفاده از هر ماژول با مثال‌های ساده توضیح داده می‌شود. برای اجرای مثال‌ها ابتدا باید پوشهٔ پروژه را در متغیر محیطی `PYTHONPATH` اضافه کنید یا اسکریپت‌های خود را در همان پوشه اجرا کنید.

### ۱. طبقه‌بندی اسناد با GCN

در این مثال سه خبر ساده در سه دستهٔ «سیاسی»، «ورزشی» و «هنری» داریم. ابتدا متن‌ها را توکنایز می‌کنیم، سپس با `build_text_graph` گرافی شامل کلمات و اسناد می‌سازیم و در نهایت یک مدل GCN برای طبقه‌بندی اسناد آموزش می‌دهیم.

```python
import sys
import numpy as np
import torch
sys.path.append('مسیر/به/پروژه')  # مسیر پوشهٔ rakhshai_graph_nlp
from rakhshai_graph_nlp.features.pyg_data import graph_to_data
from rakhshai_graph_nlp.features.tokenizer import tokenize
from rakhshai_graph_nlp.graphs.text_graph import build_text_graph
from rakhshai_graph_nlp.tasks.classification import train_gcn_classifier

docs = [
    "این یک خبر سیاسی است و دربارهٔ انتخابات صحبت می‌کند.",
    "تیم فوتبال امروز بازی مهمی دارد و همه منتظر نتیجه هستند.",
    "نمایشگاه جدید هنری با آثار نقاشان جوان افتتاح شد."
]
labels = np.array([0, 1, 2])  # برچسب اسناد به ترتیب

# توکنایز هر سند
tokenised = [tokenize(d) for d in docs]
# ساخت گراف TextGCN مانند
graph = build_text_graph(tokenised)
# ویژگی‌های اولیه برای هر گره: ماتریس هویت
X = np.eye(len(graph.nodes))
# ماسک آموزش: فقط گره‌های اسناد را در آموزش وارد می‌کنیم
n_words = len(graph.node_types) - len(docs)
mask = np.zeros(len(graph.nodes), dtype=bool)
mask[n_words:] = True
# تنظیم برچسب‌ها برای همهٔ گره‌ها: کلمات برچسبی ندارند، مقدار ۰ قرار می‌دهیم
all_labels = np.zeros(len(graph.nodes), dtype=int)
all_labels[n_words:] = labels

# آموزش مدل روی GPU در صورت موجود بودن
device = "cuda" if torch.cuda.is_available() else "cpu"
clf, losses = train_gcn_classifier(
    graph,
    X,
    all_labels,
    mask=mask,
    hidden_dim=8,
    num_epochs=100,
    device=device,
)

# ساخت دادهٔ PyG برای پیش‌بینی
data = graph_to_data(graph, features=X, labels=all_labels).to(device)
preds = clf.predict(data).cpu().numpy()[n_words:]
print("پیش‌بینی دسته‌بندی اسناد:", preds)
```

### ۲. خلاصه‌سازی با TextRank

```python
from rakhshai_graph_nlp.tasks.summarization import textrank_summarise
text = "این یک متن نمونه برای خلاصه‌سازی است. ما می‌خواهیم ببینیم آیا الگوریتم می‌تواند جملات مهم را پیدا کند. در نهایت جملات برتر به عنوان خلاصه ارائه می‌شوند."
summary = textrank_summarise(text, top_k=2)
print(summary)
```

### ۳. توصیه‌گر محتوا

```python
from rakhshai_graph_nlp.tasks.recommendation import recommend_similar
query = "این نمایشگاه جذاب است."
docs = ["این یک خبر سیاسی است و دربارهٔ انتخابات صحبت می‌کند.",
        "تیم فوتبال امروز بازی مهمی دارد و همه منتظر نتیجه هستند.",
        "نمایشگاه جدید هنری با آثار نقاشان جوان افتتاح شد."]
print(recommend_similar(query, docs, top_k=2))
```

### ۴. تشخیص نفرت‌پراکنی

```python
from rakhshai_graph_nlp.tasks.hate_speech import contains_hate_speech
hate_terms = ['نفرت', 'لعنت']
print(contains_hate_speech('این پیام حاوی نفرت است', hate_terms))  # True
print(contains_hate_speech('این پیام خوب است', hate_terms))       # False
```

### ۵. تحلیل شبکهٔ اجتماعی با GraphSAGE

```python
import numpy as np
from rakhshai_graph_nlp.graphs.graph import Graph
from rakhshai_graph_nlp.tasks.social_analysis import compute_social_embeddings

adjacency = np.array([[0,1,0], [1,0,1], [0,1,0]], dtype=float)
graph = Graph(nodes=['کاربرA','کاربرB','کاربرC'], adjacency=adjacency)
features = np.eye(3)  # ویژگی اولیه هر کاربر
embeddings = compute_social_embeddings(graph, features, hidden_dims=[16, 8])
print(embeddings)
```

## گسترش و مشارکت

این پروژه در حال توسعه است و از پیشنهادها و مشارکت‌های شما استقبال می‌کند. اگر قصد افزودن ویژگی جدید (مثلاً گراف معنایی با استفاده از WordNet فارسی) یا بهبود عملکرد مدل‌ها را دارید، می‌توانید در مخزن تغییرات خود را پیشنهاد کنید. همچنین اگر خطا یا باگی یافتید، لطفاً آن را گزارش دهید.

## منابع

برخی مطالب و مفاهیم این پروژه با الهام از منابع علمی زیر تهیه شده‌اند:

- **Stanza:** یک بستهٔ جامع برای تجزیهٔ متن که شامل توکن‌سازی، برچسب‌گذاری نقش دستوری، لِماتیزاسیون، تجزیهٔ نحوی و تشخیص موجودیت نام‌دار برای زبان‌های مختلف است.
- **GraphSAGE:** مدل یادگیری استقرایی که با نمونه‌گیری و تجمیع ویژگی‌های همسایه، embedding گره‌های جدید را تولید می‌کند و برای گراف‌های بزرگ و پویا مناسب است.
- **TextRank:** الگوریتمی که یک گراف از کلمات (یا جملات) می‌سازد و با اجرای PageRank مهم‌ترین واحدها را برای استخراج خلاصه انتخاب می‌کند.
- **WordNet:** پایگاه دادهٔ واژگانی که واژه‌ها را در مجموعه‌های هم‌معنا (synset) سازمان‌دهی می‌کند و روابط معنایی میان آن‌ها را نگهداری می‌کند.
- **TextGCN:** چارچوبی که گرافی از کلمات و اسناد می‌سازد و وزن edgesی کلمه–کلمه را بر اساس PMI و edgesی کلمه–سند را بر اساس TF‑IDF تعیین می‌کند.

استفاده از این کتابخانه به شما کمک می‌کند تا سریعاً پژوهش‌های مقدماتی خود را در زمینهٔ پردازش زبان فارسی مبتنی بر گراف آغاز کنید و آن را توسعه دهید.
## نتایج آزمایشی

### ارزیابی طبقه‌بندی متن
خروجی `build_text_graph` و آموزش GCN روی یک مجموعهٔ کوچک آزمایشی:
- **دقت:** 0.33
- **F1 کلان:** 0.17
- **F1 خرد:** 0.33

### ارزیابی خلاصه‌سازی (TextRank)
مقادیر ROUGE برای یک خبر نمونه:
| تعداد جملات خلاصه | ROUGE-1 | ROUGE-2 | ROUGE-L |
| --- | --- | --- | --- |
| 3 | 0.83 | 0.64 | 0.67 |
| 5 | 0.75 | 0.73 | 0.75 |

### آزمون توصیه‌گر محتوا
- **Precision@3:** 0.33
- **NDCG@3:** 1.00

### آزمایش فشار ساخت گراف
| تابع | N (سند) | زمان (ثانیه) | اوج حافظه (MB) |
|------|---------|--------------|----------------|
| build_cooccurrence_graph | 1k | 0.54 | 0.09 |
| build_cooccurrence_graph | 10k | 5.43 | 0.09 |
| build_cooccurrence_graph | 50k | 31.43 | 0.10 |
| build_text_graph | 1k | 1.36 | 10.14 |
| build_text_graph | 10k | 12.41 | 786.62 |
| build_text_graph | 50k | خطای حافظه | 19188.09 |

نرخ رشد زمانی تقریبی:
- build_cooccurrence_graph ≈ 6.3×10⁻⁴ ثانیه برای هر سند
- build_text_graph ≈ 1.3×10⁻³ ثانیه برای هر سند (تا 10k سند)

### آزمون رگرسیون انتها به انتها
- **F1 خرد پایه:** 0.33 (آستانهٔ تغییر مجاز ±0.005)
- **هش پیش‌بینی‌ها:** `f65dc34a53c987dd5866c2ae9c65a405`
